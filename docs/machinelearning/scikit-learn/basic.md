# scikit-learn æ‰‹å†Œ

## ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€

### 1. Scikit-learn ç®€ä»‹
Scikit-learn æ˜¯åŸºäº Python çš„ç§‘å­¦è®¡ç®—åº“ï¼ˆNumPy/SciPyï¼‰æ„å»ºçš„æœºå™¨å­¦ä¹ åº“ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

- ç®€å•é«˜æ•ˆçš„æ•°æ®æŒ–æ˜å’Œæ•°æ®åˆ†æå·¥å…·
- å¼€æºã€å•†ä¸šå¯ç”¨ - BSD è®¸å¯è¯
- å»ºç«‹åœ¨ NumPyã€SciPy å’Œ matplotlib ä¹‹ä¸Š
- æ”¯æŒç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ ç®—æ³•

### 2. å®‰è£…ä¸é…ç½®
```bash
# åŸºç¡€å®‰è£…
pip install scikit-learn

# å®Œæ•´å®‰è£…ï¼ˆåŒ…å«ç»˜å›¾åŠŸèƒ½ï¼‰
pip install scikit-learn[alldeps]

# éªŒè¯å®‰è£…
python -c "import sklearn; print(sklearn.__version__)"
```

### 3. åŸºæœ¬å·¥ä½œæµç¨‹


| æ­¥éª¤ | æ–¹æ³• |
|------|------|
| 1ï¸âƒ£ æ•°æ®é¢„å¤„ç† | `preprocessing` |
| 2ï¸âƒ£ åˆ’åˆ†è®­ç»ƒé›†æµ‹è¯•é›† | `train_test_split()` |
| 3ï¸âƒ£ é€‰æ‹©æ¨¡å‹ | `LogisticRegression()`ã€`SVC()` ç­‰ |
| 4ï¸âƒ£ æ¨¡å‹è®­ç»ƒ | `.fit(X_train, y_train)` |
| 5ï¸âƒ£ æ¨¡å‹é¢„æµ‹ | `.predict(X_test)` |
| 6ï¸âƒ£ æ¨¡å‹è¯„ä¼° | `accuracy_score`ã€`classification_report` ç­‰ |

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# åŠ è½½æ•°æ®
iris = load_iris()
X, y = iris.data, iris.target

# æ•°æ®åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# æ•°æ®æ ‡å‡†åŒ–
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# æ¨¡å‹è®­ç»ƒ
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# æ¨¡å‹è¯„ä¼°
y_pred = clf.predict(X_test)
print(f"å‡†ç¡®ç‡: {accuracy_score(y_test, y_pred):.2f}")
```

## ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒæ¨¡å—

| æ¨¡å— | ä½œç”¨ |
|------|------|
| `sklearn.datasets` | åŠ è½½å†…ç½®æ•°æ®é›† |
| `sklearn.model_selection` | è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†ï¼Œäº¤å‰éªŒè¯ï¼Œç½‘æ ¼æœç´¢ |
| `sklearn.preprocessing` | æ•°æ®æ ‡å‡†åŒ–ã€å½’ä¸€åŒ–ã€ç¼–ç ç­‰ |
| `sklearn.metrics` | æ¨¡å‹è¯„ä¼° |
| `sklearn.linear_model` | çº¿æ€§æ¨¡å‹ï¼Œå¦‚çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ |
| `sklearn.tree` | å†³ç­–æ ‘ã€éšæœºæ£®æ—ç­‰ |
| `sklearn.svm` | æ”¯æŒå‘é‡æœº |
| `sklearn.cluster` | èšç±»ç®—æ³•ï¼Œå¦‚ KMeans |
| `sklearn.decomposition` | PCA ç­‰é™ç»´ç®—æ³• |

### 1. sklearn.datasets 

#### ğŸ§  ä¸€ã€datasets æ˜¯ä»€ä¹ˆï¼Ÿ

sklearn.datasets æä¾›äº†ï¼š

+ âœ… å†…ç½®ç»å…¸æ•°æ®é›†ï¼ˆå¦‚é¸¢å°¾èŠ±ã€æ³¢å£«é¡¿æˆ¿ä»·ï¼‰
+ âœ… ä¸‹è½½çœŸå®æ•°æ®é›†ï¼ˆå¦‚ 20 ç±»æ–°é—»æ–‡æœ¬ï¼‰
+ âœ… ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆç”¨äºåˆ†ç±»ã€å›å½’ã€èšç±»ç­‰ï¼‰

#### ğŸ“š äºŒã€å†…ç½®å°å‹æ•°æ®é›†ï¼ˆå¸¸ç”¨äºå…¥é—¨ç»ƒä¹ ï¼‰

| å‡½æ•°å | æè¿° |
|--------|------|
| `load_iris()` | é¸¢å°¾èŠ±æ•°æ®é›†ï¼ˆåˆ†ç±»ï¼‰ |
| `load_digits()` | æ‰‹å†™æ•°å­—æ•°æ®é›† |
| `load_diabetes()` | ç³–å°¿ç—…æ•°æ®é›†ï¼ˆå›å½’ï¼‰ |
| `load_wine()` | è‘¡è„é…’åˆ†ç±»æ•°æ® |
| `load_breast_cancer()` | ä¹³è…ºç™ŒäºŒåˆ†ç±»æ•°æ® |
| `load_linnerud()` | äººä½“æŒ‡æ ‡å›å½’æ•°æ® |


#### ğŸŒ ä¸‰ã€ä»å¤–éƒ¨ä¸‹è½½æ•°æ®é›†ï¼ˆçœŸå®ä¸–ç•Œï¼‰

| å‡½æ•°å | æè¿° |
|--------|------|
| `fetch_20newsgroups()` | 20 ç±»æ–°é—»æ–‡æœ¬ï¼ˆNLPï¼‰ |
| `fetch_california_housing()` | åŠ å·æˆ¿ä»·æ•°æ®ï¼ˆå›å½’ï¼‰ |
| `fetch_covtype()` | æ£®æ—è¦†ç›–ç±»å‹æ•°æ®é›† |
| `fetch_olivetti_faces()` | Olivetti äººè„¸è¯†åˆ«å›¾åƒæ•°æ® |
| `fetch_lfw_people()` | LFWï¼ˆLabeled Faces in the Wildï¼‰äººè„¸å›¾åƒ |
| `fetch_lfw_pairs()` | LFW è„¸éƒ¨é…å¯¹å›¾åƒï¼ˆäººè„¸éªŒè¯ï¼‰ |


#### ğŸ§ª å››ã€ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆå»ºæ¨¡ä¸æµ‹è¯•ç”¨ï¼‰

| å‡½æ•° | ç”¨é€” |
|------|------|
| `make_classification()` | ç”Ÿæˆç”¨äºåˆ†ç±»çš„æ ·æœ¬æ•°æ® |
| `make_regression()` | ç”Ÿæˆç”¨äºå›å½’çš„æ ·æœ¬æ•°æ® |
| `make_blobs()` | ç”Ÿæˆç”¨äºèšç±»æµ‹è¯•çš„é«˜æ–¯åˆ†å¸ƒæ•°æ® |
| `make_moons()` | ç”ŸæˆåŒæœˆå½¢çŠ¶çš„éçº¿æ€§åˆ†ç±»æ•°æ® |
| `make_circles()` | ç”ŸæˆåŒå¿ƒåœ†å½¢çš„äºŒåˆ†ç±»æ•°æ® |
| `make_multilabel_classification()` | ç”Ÿæˆå¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜æ•°æ® |
| `make_sparse_spd_matrix()` | ç”Ÿæˆç¨€ç–å¯¹ç§°æ­£å®šçŸ©é˜µï¼ˆå¦‚å›¾æ¨¡å‹ç»“æ„ï¼‰ |


### 2. sklearn.model_selection

#### ğŸ“Œ ä¸€ã€model_selection æ˜¯ä»€ä¹ˆï¼Ÿ

è¿™æ˜¯ scikit-learn ä¸­è´Ÿè´£ï¼š

+	æ•°æ®åˆ’åˆ†ï¼ˆè®­ç»ƒé›†/æµ‹è¯•é›†ï¼‰
+	æ¨¡å‹è¯„ä¼°ï¼ˆäº¤å‰éªŒè¯ï¼‰
+	è¶…å‚æ•°æœç´¢ï¼ˆç½‘æ ¼æœç´¢ã€éšæœºæœç´¢ï¼‰
+	æ¨¡å‹é€‰æ‹©ä¸éªŒè¯ç­–ç•¥çš„æ ¸å¿ƒæ¨¡å—


#### ğŸ§© äºŒã€å¸¸ç”¨åŠŸèƒ½åˆ†ç±»ä¸ä½œç”¨

| åŠŸèƒ½ç±»åˆ« | å¸¸ç”¨å‡½æ•° | ä½œç”¨ |
|----------|----------|------|
| æ•°æ®é›†åˆ’åˆ† | `train_test_split` | è®­ç»ƒé›† / æµ‹è¯•é›†åˆ’åˆ† |
| äº¤å‰éªŒè¯ | `cross_val_score`, `cross_validate`, `KFold`, `StratifiedKFold` | å¤šæŠ˜è¯„ä¼°æ¨¡å‹ |
| è¶…å‚æ•°æœç´¢ | `GridSearchCV`, `RandomizedSearchCV` | ç½‘æ ¼/éšæœºæœç´¢å‚æ•° |
| å­¦ä¹ æ›²çº¿ | `learning_curve`, `validation_curve` | æ¨¡å‹å­¦ä¹ è¿‡ç¨‹å¯è§†åŒ– |
| é¢„å®šä¹‰éªŒè¯ | `ShuffleSplit`, `LeaveOneOut` ç­‰ | æ§åˆ¶éªŒè¯é›†åˆ’åˆ†æ–¹å¼ |


#### âœ‚ï¸ ä¸‰ã€æ•°æ®åˆ’åˆ†ï¼štrain_test_split()

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2,
                                                    random_state=42,
                                                    stratify=y)
```

+	test_sizeï¼šæµ‹è¯•é›†æ¯”ä¾‹ï¼ˆå¦‚ 0.2ï¼‰
+	stratify=yï¼šæŒ‰æ ‡ç­¾æ¯”ä¾‹åˆ†å±‚é‡‡æ ·ï¼ˆåˆ†ç±»å¸¸ç”¨ï¼‰


#### ğŸ” å››ã€äº¤å‰éªŒè¯

##### 1ï¸âƒ£ cross_val_score()

å¿«é€Ÿè¯„ä¼°æ¨¡å‹äº¤å‰éªŒè¯å¾—åˆ†ï¼š

```python
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression

scores = cross_val_score(LogisticRegression(), X, y, cv=5)
print("å¹³å‡å‡†ç¡®ç‡ï¼š", scores.mean())
```

##### 2ï¸âƒ£ cross_validate()ï¼ˆæ”¯æŒæ›´å¤šè¾“å‡ºï¼‰

```python
from sklearn.model_selection import cross_validate

result = cross_validate(LogisticRegression(), X, y,
                        scoring=['accuracy', 'f1_macro'],
                        return_train_score=True,
                        cv=5)
print(result)
```

#### ğŸ”€ äº”ã€äº¤å‰éªŒè¯ç­–ç•¥ç±»ï¼ˆKFold ç­‰ï¼‰

| ç±»å | è¯´æ˜ |
|------|------|
| `KFold` | ç®€å•å‡åŒ€åˆ’åˆ†ä¸º K æŠ˜ |
| `StratifiedKFold` | ä¿æŒç±»åˆ«åˆ†å¸ƒçš„ K æŠ˜ï¼ˆé€‚ç”¨äºåˆ†ç±»é—®é¢˜ï¼‰ |
| `ShuffleSplit` | å¤šæ¬¡éšæœºåˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›† |
| `LeaveOneOut` | ç•™ä¸€æ³•ï¼ˆæ¯æ¬¡ç•™ä¸€ä¸ªæ ·æœ¬åšæµ‹è¯•é›†ï¼‰ |
| `GroupKFold` | æŒ‰ç»„åˆ’åˆ†ï¼Œç¡®ä¿åŒä¸€ç»„æ•°æ®ä¸åœ¨è®­ç»ƒå’ŒéªŒè¯é›†ä¸­åŒæ—¶å‡ºç° |


```python
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=5)
for train_idx, test_idx in skf.split(X, y):
    print(train_idx, test_idx)
```

#### ğŸ” å…­ã€è¶…å‚æ•°æœç´¢

##### âœ… GridSearchCVï¼ˆç½‘æ ¼æœç´¢ï¼‰

```python
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
grid = GridSearchCV(SVC(), param_grid, cv=5)
grid.fit(X_train, y_train)

print("æœ€ä¼˜å‚æ•°ï¼š", grid.best_params_)
print("æœ€ä¼˜å¾—åˆ†ï¼š", grid.best_score_)
```
