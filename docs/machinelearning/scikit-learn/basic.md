# scikit-learn æ‰‹å†Œ

## ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€

### 1. Scikit-learn ç®€ä»‹
Scikit-learn æ˜¯åŸºäº Python çš„ç§‘å­¦è®¡ç®—åº“ï¼ˆNumPy/SciPyï¼‰æ„å»ºçš„æœºå™¨å­¦ä¹ åº“ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

- ç®€å•é«˜æ•ˆçš„æ•°æ®æŒ–æ˜å’Œæ•°æ®åˆ†æå·¥å…·
- å¼€æºã€å•†ä¸šå¯ç”¨ - BSD è®¸å¯è¯
- å»ºç«‹åœ¨ NumPyã€SciPy å’Œ matplotlib ä¹‹ä¸Š
- æ”¯æŒç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ ç®—æ³•

### 2. å®‰è£…ä¸é…ç½®
```bash
# åŸºç¡€å®‰è£…
pip install scikit-learn

# å®Œæ•´å®‰è£…ï¼ˆåŒ…å«ç»˜å›¾åŠŸèƒ½ï¼‰
pip install scikit-learn[alldeps]

# éªŒè¯å®‰è£…
python -c "import sklearn; print(sklearn.__version__)"
```

### 3. åŸºæœ¬å·¥ä½œæµç¨‹


| æ­¥éª¤ | æ–¹æ³• |
|------|------|
| 1ï¸âƒ£ æ•°æ®é¢„å¤„ç† | `preprocessing` |
| 2ï¸âƒ£ åˆ’åˆ†è®­ç»ƒé›†æµ‹è¯•é›† | `train_test_split()` |
| 3ï¸âƒ£ é€‰æ‹©æ¨¡å‹ | `LogisticRegression()`ã€`SVC()` ç­‰ |
| 4ï¸âƒ£ æ¨¡å‹è®­ç»ƒ | `.fit(X_train, y_train)` |
| 5ï¸âƒ£ æ¨¡å‹é¢„æµ‹ | `.predict(X_test)` |
| 6ï¸âƒ£ æ¨¡å‹è¯„ä¼° | `accuracy_score`ã€`classification_report` ç­‰ |

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# åŠ è½½æ•°æ®
iris = load_iris()
X, y = iris.data, iris.target

# æ•°æ®åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# æ•°æ®æ ‡å‡†åŒ–
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# æ¨¡å‹è®­ç»ƒ
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# æ¨¡å‹è¯„ä¼°
y_pred = clf.predict(X_test)
print(f"å‡†ç¡®ç‡: {accuracy_score(y_test, y_pred):.2f}")
```

## ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒæ¨¡å—

| æ¨¡å— | ä½œç”¨ |
|------|------|
| `sklearn.datasets` | åŠ è½½å†…ç½®æ•°æ®é›† |
| `sklearn.model_selection` | è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†ï¼Œäº¤å‰éªŒè¯ï¼Œç½‘æ ¼æœç´¢ |
| `sklearn.preprocessing` | æ•°æ®æ ‡å‡†åŒ–ã€å½’ä¸€åŒ–ã€ç¼–ç ç­‰ |
| `sklearn.metrics` | æ¨¡å‹è¯„ä¼° |
| `sklearn.linear_model` | çº¿æ€§æ¨¡å‹ï¼Œå¦‚çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ |
| `sklearn.tree` | å†³ç­–æ ‘ã€éšæœºæ£®æ—ç­‰ |
| `sklearn.svm` | æ”¯æŒå‘é‡æœº |
| `sklearn.cluster` | èšç±»ç®—æ³•ï¼Œå¦‚ KMeans |
| `sklearn.decomposition` | PCA ç­‰é™ç»´ç®—æ³• |

### 1. sklearn.datasets 

#### ğŸ§  ä¸€ã€datasets æ˜¯ä»€ä¹ˆï¼Ÿ

sklearn.datasets æä¾›äº†ï¼š

+ âœ… å†…ç½®ç»å…¸æ•°æ®é›†ï¼ˆå¦‚é¸¢å°¾èŠ±ã€æ³¢å£«é¡¿æˆ¿ä»·ï¼‰
+ âœ… ä¸‹è½½çœŸå®æ•°æ®é›†ï¼ˆå¦‚ 20 ç±»æ–°é—»æ–‡æœ¬ï¼‰
+ âœ… ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆç”¨äºåˆ†ç±»ã€å›å½’ã€èšç±»ç­‰ï¼‰

#### ğŸ“š äºŒã€å†…ç½®å°å‹æ•°æ®é›†ï¼ˆå¸¸ç”¨äºå…¥é—¨ç»ƒä¹ ï¼‰

| å‡½æ•°å | æè¿° |
|--------|------|
| `load_iris()` | é¸¢å°¾èŠ±æ•°æ®é›†ï¼ˆåˆ†ç±»ï¼‰ |
| `load_digits()` | æ‰‹å†™æ•°å­—æ•°æ®é›† |
| `load_diabetes()` | ç³–å°¿ç—…æ•°æ®é›†ï¼ˆå›å½’ï¼‰ |
| `load_wine()` | è‘¡è„é…’åˆ†ç±»æ•°æ® |
| `load_breast_cancer()` | ä¹³è…ºç™ŒäºŒåˆ†ç±»æ•°æ® |
| `load_linnerud()` | äººä½“æŒ‡æ ‡å›å½’æ•°æ® |


#### ğŸŒ ä¸‰ã€ä»å¤–éƒ¨ä¸‹è½½æ•°æ®é›†ï¼ˆçœŸå®ä¸–ç•Œï¼‰

| å‡½æ•°å | æè¿° |
|--------|------|
| `fetch_20newsgroups()` | 20 ç±»æ–°é—»æ–‡æœ¬ï¼ˆNLPï¼‰ |
| `fetch_california_housing()` | åŠ å·æˆ¿ä»·æ•°æ®ï¼ˆå›å½’ï¼‰ |
| `fetch_covtype()` | æ£®æ—è¦†ç›–ç±»å‹æ•°æ®é›† |
| `fetch_olivetti_faces()` | Olivetti äººè„¸è¯†åˆ«å›¾åƒæ•°æ® |
| `fetch_lfw_people()` | LFWï¼ˆLabeled Faces in the Wildï¼‰äººè„¸å›¾åƒ |
| `fetch_lfw_pairs()` | LFW è„¸éƒ¨é…å¯¹å›¾åƒï¼ˆäººè„¸éªŒè¯ï¼‰ |


#### ğŸ§ª å››ã€ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆå»ºæ¨¡ä¸æµ‹è¯•ç”¨ï¼‰

| å‡½æ•° | ç”¨é€” |
|------|------|
| `make_classification()` | ç”Ÿæˆç”¨äºåˆ†ç±»çš„æ ·æœ¬æ•°æ® |
| `make_regression()` | ç”Ÿæˆç”¨äºå›å½’çš„æ ·æœ¬æ•°æ® |
| `make_blobs()` | ç”Ÿæˆç”¨äºèšç±»æµ‹è¯•çš„é«˜æ–¯åˆ†å¸ƒæ•°æ® |
| `make_moons()` | ç”ŸæˆåŒæœˆå½¢çŠ¶çš„éçº¿æ€§åˆ†ç±»æ•°æ® |
| `make_circles()` | ç”ŸæˆåŒå¿ƒåœ†å½¢çš„äºŒåˆ†ç±»æ•°æ® |
| `make_multilabel_classification()` | ç”Ÿæˆå¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜æ•°æ® |
| `make_sparse_spd_matrix()` | ç”Ÿæˆç¨€ç–å¯¹ç§°æ­£å®šçŸ©é˜µï¼ˆå¦‚å›¾æ¨¡å‹ç»“æ„ï¼‰ |


