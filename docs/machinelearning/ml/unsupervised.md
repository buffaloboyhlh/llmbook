# 第五章：非监督学习

### 1️⃣ 什么是无监督学习？

**无监督学习**是一类在没有标签数据的情况下，通过分析数据的结构、分布或隐藏模式来进行学习的方法。  
常用于数据探索、聚类、降维、异常检测等任务。

---

### 2️⃣ 无监督学习 vs 监督学习

| 比较维度   | 无监督学习                       | 监督学习                           |
|------------|----------------------------------|------------------------------------|
| 是否有标签 | ❌ 无标签                         | ✅ 有标签                          |
| 学习目标   | 挖掘结构、分布、规律             | 学习输入与输出的映射关系           |
| 应用类型   | 聚类、降维、关联分析、异常检测等 | 分类、回归、序列标注等             |
| 常见算法   | K-Means、PCA、AutoEncoder等      | 决策树、SVM、神经网络等            |

---

### 3️⃣ 常见的无监督学习模型

| 模型名称         | 类型       | 简介与应用                                       |
|------------------|------------|--------------------------------------------------|
| K-Means 聚类     | 聚类       | 将数据划分为 \(k\) 个簇，适合球形聚类             |
| DBSCAN           | 聚类       | 基于密度的聚类，适用于任意形状簇，能发现异常点     |
| 层次聚类         | 聚类       | 构建聚类树状结构，可进行分层聚类                   |
| PCA              | 降维       | 寻找主成分方向，常用于数据压缩与可视化             |
| t-SNE            | 降维       | 保留局部结构，适合高维可视化                       |
| UMAP             | 降维       | 保持拓扑结构，速度更快，支持大规模数据             |
| AutoEncoder      | 降维/重建  | 使用神经网络编码输入表示，适合非线性特征压缩       |
| Apriori / FP-Growth | 关联分析 | 挖掘频繁项集与关联规则，用于推荐系统与市场分析     |

---

### 4️⃣ K-Means 聚类算法

#### 📌 算法流程：

1. 随机选择 \(k\) 个初始聚类中心
2. 将每个样本分配给最近的中心
3. 重新计算每个簇的质心
4. 重复步骤 2 和 3，直到聚类中心收敛

#### ✅ 优点：
- 简单高效，易于实现
- 适合大规模样本

#### ⚠️ 缺点：
- 需预先设定 \(k\)
- 对初始中心敏感
- 不适合非凸形状或密度不同的簇

---

### 5️⃣ PCA 主成分分析

PCA 是一种线性降维方法，通过投影到最大方差方向实现维度压缩。

#### 数学表达：

1. 对样本矩阵 \(X \in \mathbb{R}^{n \times d}\) 标准化  
2. 计算协方差矩阵：  
   $$
   C = \frac{1}{n} X^T X
   $$
3. 进行特征值分解：  
   $$
   C = V \Lambda V^T
   $$
4. 选择前 \(k\) 个最大特征值对应的特征向量 \(W_k\)
5. 投影至低维空间：  
   $$
   X_{\text{new}} = X W_k
   $$

---

### 6️⃣ AutoEncoder 简介

AutoEncoder 是一种无监督神经网络结构，用于学习低维编码。

#### 结构：

输入层 → 编码器 → 潜层表示（低维） → 解码器 → 重构输出层

- 编码器压缩输入信息
- 解码器尝试还原输入
- 损失函数通常为重构误差（如 MSE）

---

### 7️⃣ Python 示例：K-Means + 可视化

```python
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# 生成样本数据
X, y = make_blobs(n_samples=300, centers=3, random_state=42)

# 建立模型
kmeans = KMeans(n_clusters=3, random_state=42)
labels = kmeans.fit_predict(X)

# 可视化聚类结果
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.scatter(kmeans.cluster_centers_[:, 0],
            kmeans.cluster_centers_[:, 1],
            s=200, c='red', marker='X')
plt.title("K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()
```

### 8️⃣ 无监督学习的应用场景

| 应用领域       | 实例说明                               |
|----------------|----------------------------------------|
| 客户细分       | 根据用户行为进行聚类，进行个性化营销   |
| 图像压缩       | 利用 AutoEncoder 降低图像存储空间       |
| 异常检测       | 识别网络攻击、信用卡欺诈等异常行为     |
| 数据可视化     | 使用 PCA、t-SNE 或 UMAP 将高维数据降维 |
| 推荐系统       | 基于用户行为相似性或关联规则推荐商品   |

### 9️⃣ 总结

| 方法          | 类型     | 典型应用                   | 是否需指定超参         |
|---------------|----------|----------------------------|------------------------|
| K-Means       | 聚类     | 客户分群、图像分割         | ✅ 需要指定聚类数 \(k\)   |
| DBSCAN        | 聚类     | 异常检测、空间聚类         | ✅ 需要设置半径和最小点数 |
| PCA           | 降维     | 数据压缩、特征提取、预处理 | ✅ 需要设定降维目标维度   |
| AutoEncoder   | 降维     | 图像压缩、非线性特征学习   | ✅ 需要设定网络结构       |
| t-SNE / UMAP  | 降维     | 高维数据可视化             | ✅ 有多个可调参数         |




