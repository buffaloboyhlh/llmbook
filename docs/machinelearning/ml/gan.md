# ç¬¬åä¸‰ç« ï¼šç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ

---

## ğŸ§  ä¸€ã€ä»€ä¹ˆæ˜¯ GANï¼Ÿ

**ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰** æ˜¯ä¸€ç§å¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹ï¼Œç”± Ian Goodfellow ç­‰äººåœ¨ 2014 å¹´æå‡ºï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡ä¸¤ä¸ªç¥ç»ç½‘ç»œä¹‹é—´çš„åšå¼ˆè®­ç»ƒï¼Œä»è€Œç”Ÿæˆä»¥å‡ä¹±çœŸçš„æ•°æ®æ ·æœ¬ã€‚

### âœ¨ GAN åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼š

- **ç”Ÿæˆå™¨ï¼ˆGeneratorï¼Œ$G$ï¼‰**ï¼šæ¥å—éšæœºå™ªå£° $z$ï¼Œç”Ÿæˆä¼ªé€ æ•°æ® $G(z)$ã€‚
- **åˆ¤åˆ«å™¨ï¼ˆDiscriminatorï¼Œ$D$ï¼‰**ï¼šåˆ¤æ–­è¾“å…¥æ•°æ®æ˜¯çœŸå®çš„ï¼ˆæ¥è‡ªè®­ç»ƒé›†ï¼‰è¿˜æ˜¯ä¼ªé€ çš„ï¼ˆæ¥è‡ªç”Ÿæˆå™¨ï¼‰ã€‚

äºŒè€…é€šè¿‡å¯¹æŠ—è®­ç»ƒï¼Œä¸æ–­ä¼˜åŒ–ï¼Œä½¿å¾—ç”Ÿæˆå™¨èƒ½ç”Ÿæˆæ›´é€¼çœŸçš„æ ·æœ¬ï¼Œè€Œåˆ¤åˆ«å™¨èƒ½æ›´å‡†ç¡®åœ°åŒºåˆ†çœŸå‡ã€‚

---

## ğŸ“ äºŒã€åŸºæœ¬åŸç†ä¸æ•°å­¦å…¬å¼

### 1. ç›®æ ‡å‡½æ•°ï¼ˆMinimax åšå¼ˆï¼‰

GAN çš„ç›®æ ‡æ˜¯ä¸€ä¸ªæå°æå¤§é—®é¢˜ï¼š

$$
\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{\text{data}}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
$$

å…¶ä¸­ï¼š

- $x$ï¼šçœŸå®æ ·æœ¬
- $z$ï¼šç”Ÿæˆå™¨çš„è¾“å…¥å™ªå£°
- $G(z)$ï¼šç”Ÿæˆæ ·æœ¬
- $D(x)$ï¼šåˆ¤åˆ«å™¨è®¤ä¸º $x$ ä¸ºçœŸå®æ ·æœ¬çš„æ¦‚ç‡
- $p_{\text{data}}$ï¼šçœŸå®æ•°æ®çš„åˆ†å¸ƒ
- $p_z$ï¼šå™ªå£°åˆ†å¸ƒï¼ˆé€šå¸¸ä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼‰

---

## ğŸ§ª ä¸‰ã€PyTorch å®ç°ï¼ˆMNIST ç¤ºä¾‹ï¼‰

### 1. æ¨¡å‹ç»“æ„

```python
import torch
import torch.nn as nn

# ç”Ÿæˆå™¨
class Generator(nn.Module):
    def __init__(self, noise_dim=100, output_dim=784):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(noise_dim, 256), nn.ReLU(),
            nn.Linear(256, 512), nn.ReLU(),
            nn.Linear(512, output_dim), nn.Tanh()
        )
    def forward(self, z):
        return self.model(z)

# åˆ¤åˆ«å™¨
class Discriminator(nn.Module):
    def __init__(self, input_dim=784):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 512), nn.LeakyReLU(0.2),
            nn.Linear(512, 256), nn.LeakyReLU(0.2),
            nn.Linear(256, 1), nn.Sigmoid()
        )
    def forward(self, x):
        return self.model(x)
```

---

### 2. è®­ç»ƒè¿‡ç¨‹

```python
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# åˆå§‹åŒ–æ¨¡å‹ä¸ä¼˜åŒ–å™¨
G = Generator()
D = Discriminator()
criterion = nn.BCELoss()
optimizer_G = optim.Adam(G.parameters(), lr=0.0002)
optimizer_D = optim.Adam(D.parameters(), lr=0.0002)

# åŠ è½½ MNIST æ•°æ®
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.view(-1)),
    transforms.Normalize(0.5, 0.5)
])
dataloader = DataLoader(
    datasets.MNIST(root="./data", train=True, transform=transform, download=True),
    batch_size=64, shuffle=True
)

# è®­ç»ƒå¾ªç¯
for epoch in range(50):
    for real_data, _ in dataloader:
        batch_size = real_data.size(0)
        real_labels = torch.ones(batch_size, 1)
        fake_labels = torch.zeros(batch_size, 1)

        # è®­ç»ƒåˆ¤åˆ«å™¨
        z = torch.randn(batch_size, 100)
        fake_data = G(z)
        real_output = D(real_data)
        fake_output = D(fake_data.detach())
        D_loss = criterion(real_output, real_labels) + criterion(fake_output, fake_labels)

        optimizer_D.zero_grad()
        D_loss.backward()
        optimizer_D.step()

        # è®­ç»ƒç”Ÿæˆå™¨
        output = D(fake_data)
        G_loss = criterion(output, real_labels)

        optimizer_G.zero_grad()
        G_loss.backward()
        optimizer_G.step()

    print(f"Epoch {epoch}: D_loss={D_loss.item():.4f}, G_loss={G_loss.item():.4f}")
```

---

## ğŸ“Š å››ã€å¸¸è§é—®é¢˜ä¸æ”¹è¿›

| é—®é¢˜                 | åŸå› ä¸è§£å†³æ–¹æ³•                                         |
|----------------------|--------------------------------------------------------|
| è®­ç»ƒä¸ç¨³å®š           | ä½¿ç”¨ WGANã€è°ƒæ•´ç½‘ç»œç»“æ„ã€ä½¿ç”¨å½’ä¸€åŒ–ç­‰                 |
| æ¨¡å¼å´©æºƒï¼ˆMode Collapseï¼‰ | åŠ å…¥å™ªå£°ã€æ”¹è¿›ç½‘ç»œç»“æ„ï¼ˆå¦‚ Unrolled GANï¼‰            |
| åˆ¤åˆ«å™¨è¿‡å¼ºæˆ–è¿‡å¼±     | ä¿æŒ G å’Œ D çš„è®­ç»ƒå¹³è¡¡ï¼›ä½¿ç”¨æ ‡ç­¾å¹³æ»‘ã€æ¢¯åº¦æƒ©ç½šç­‰       |

---

## ğŸš€ äº”ã€å¸¸è§ GAN å˜ä½“

| å˜ä½“       | ç‰¹ç‚¹æè¿°                                             |
|------------|------------------------------------------------------|
| DCGAN      | ä½¿ç”¨ CNN æ¶æ„ï¼Œæå‡å›¾åƒç”Ÿæˆæ•ˆæœ                      |
| CGAN       | æ¡ä»¶ GANï¼Œç”Ÿæˆç‰¹å®šç±»åˆ«æ ·æœ¬ï¼ˆå¦‚è¾“å…¥æ ‡ç­¾ï¼‰            |
| WGAN       | ä½¿ç”¨ Wasserstein è·ç¦»ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§                |
| WGAN-GP    | WGAN åŠ å…¥æ¢¯åº¦æƒ©ç½šï¼Œè¿›ä¸€æ­¥æ”¹å–„æ”¶æ•›æ€§                  |
| LSGAN      | ä½¿ç”¨æœ€å°äºŒä¹˜æŸå¤±ï¼Œå‡å°‘æ¢¯åº¦æ¶ˆå¤±                       |
| StyleGAN   | é«˜è´¨é‡äººè„¸ç”Ÿæˆï¼Œæ§åˆ¶é£æ ¼ä¸å†…å®¹                       |
| CycleGAN   | æ— éœ€æˆå¯¹å›¾åƒè¿›è¡Œé£æ ¼è¿ç§»ï¼ˆå¦‚å°†é©¬å˜æˆæ–‘é©¬ï¼‰           |

---

## ğŸ§± å…­ã€åº”ç”¨åœºæ™¯

- å›¾åƒç”Ÿæˆã€ä¸Šè‰²ä¸ä¿®å¤
- å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSRGANï¼‰
- å›¾åƒé£æ ¼è½¬æ¢ï¼ˆCycleGANï¼‰
- æ•°æ®å¢å¼ºï¼ˆData Augmentationï¼‰
- éŸ³ä¹ä¸è¯­éŸ³ç”Ÿæˆ
- æ–‡æœ¬ç”Ÿæˆï¼ˆseqGAN ç­‰ï¼‰
- åŒ»ç–—å›¾åƒåˆæˆä¸æ•°æ®è¡¥å…¨

---

## ğŸ“š ä¸ƒã€æ¨èèµ„æº

- è®ºæ–‡åŸæ–‡ï¼š[Generative Adversarial Nets (2014)](https://arxiv.org/abs/1406.2661)
- å®è·µæ•™ç¨‹ï¼šTensorFlow / PyTorch å®˜æ–¹æ–‡æ¡£
- GitHub ç¤ºä¾‹é¡¹ç›®ï¼š`pytorch/examples`, `eriklindernoren/PyTorch-GAN`

